{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Habram\\Anaconda3\\envs\\LayoutXLM\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Found cached dataset istvoices_dataset (C:/Users/Habram/.cache/istvoices_dataset/IstVoices/1.0.0/4660e7525df72d5cbd07d0b01b4a094546e5d7b1700b7556937b856c19b5b051)\n",
      "100%|██████████| 2/2 [00:00<00:00, 57.84it/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load the custom dataset (or it if it does not exist)\n",
    "# Param 1: location of the dataset loader script\n",
    "# Param 2: location of cache folder, where the dataset will be saved\n",
    "dataset = load_dataset(r'C:\\Users\\Habram\\Documents\\thesis-masters\\invoice_generation\\istvoices_dataset.py', \n",
    "                        cache_dir=r'C:\\Users\\Habram\\.cache')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'tokens', 'bboxes', 'ner_tags', 'image'],\n",
       "        num_rows: 141\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'tokens', 'bboxes', 'ner_tags', 'image'],\n",
       "        num_rows: 47\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': Value(dtype='string', id=None),\n",
       " 'tokens': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None),\n",
       " 'bboxes': Sequence(feature=Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None), length=-1, id=None),\n",
       " 'ner_tags': Sequence(feature=ClassLabel(names=['B-R_NAME', 'B-R_STREET', 'B-R_HOUSENUMBER', 'B-R_ZIP', 'B-R_CITY', 'B-R_COUNTRY', 'B-R_VAT', 'I-R_NAME', 'I-R_STREET', 'I-R_HOUSENUMBER', 'I-R_ZIP', 'I-R_CITY', 'I-R_COUNTRY', 'I-R_VAT', 'B-S_NAME', 'B-S_STREET', 'B-S_HOUSENUMBER', 'B-S_ZIP', 'B-S_CITY', 'B-S_COUNTRY', 'B-S_VAT', 'I-S_NAME', 'I-S_STREET', 'I-S_HOUSENUMBER', 'I-S_ZIP', 'I-S_CITY', 'I-S_COUNTRY', 'I-S_VAT', 'B-S_BANK', 'B-S_BIC', 'B-S_IBAN', 'B-S_TEL', 'B-S_EMAIL', 'I-S_BANK', 'I-S_BIC', 'I-S_IBAN', 'I-S_TEL', 'I-S_EMAIL', 'B-I_NUMBER', 'B-I_DATE', 'B-I_DUEDATE', 'B-I_AMOUNT', 'B-I_CURRENCY', 'I-I_NUMBER', 'I-I_DATE', 'I-I_DUEDATE', 'I-I_AMOUNT', 'I-I_CURRENCY', 'OTHER'], id=None), length=-1, id=None),\n",
       " 'image': Image(decode=True, id=None)}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'].features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-R_NAME', 'B-R_STREET', 'B-R_HOUSENUMBER', 'B-R_ZIP', 'B-R_CITY', 'B-R_COUNTRY', 'B-R_VAT', 'I-R_NAME', 'I-R_STREET', 'I-R_HOUSENUMBER', 'I-R_ZIP', 'I-R_CITY', 'I-R_COUNTRY', 'I-R_VAT', 'B-S_NAME', 'B-S_STREET', 'B-S_HOUSENUMBER', 'B-S_ZIP', 'B-S_CITY', 'B-S_COUNTRY', 'B-S_VAT', 'I-S_NAME', 'I-S_STREET', 'I-S_HOUSENUMBER', 'I-S_ZIP', 'I-S_CITY', 'I-S_COUNTRY', 'I-S_VAT', 'B-S_BANK', 'B-S_BIC', 'B-S_IBAN', 'B-S_TEL', 'B-S_EMAIL', 'I-S_BANK', 'I-S_BIC', 'I-S_IBAN', 'I-S_TEL', 'I-S_EMAIL', 'B-I_NUMBER', 'B-I_DATE', 'B-I_DUEDATE', 'B-I_AMOUNT', 'B-I_CURRENCY', 'I-I_NUMBER', 'I-I_DATE', 'I-I_DUEDATE', 'I-I_AMOUNT', 'I-I_CURRENCY', 'OTHER']\n"
     ]
    }
   ],
   "source": [
    "labels = dataset['train'].features['ner_tags'].feature.names\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'B-R_NAME', 1: 'B-R_STREET', 2: 'B-R_HOUSENUMBER', 3: 'B-R_ZIP', 4: 'B-R_CITY', 5: 'B-R_COUNTRY', 6: 'B-R_VAT', 7: 'I-R_NAME', 8: 'I-R_STREET', 9: 'I-R_HOUSENUMBER', 10: 'I-R_ZIP', 11: 'I-R_CITY', 12: 'I-R_COUNTRY', 13: 'I-R_VAT', 14: 'B-S_NAME', 15: 'B-S_STREET', 16: 'B-S_HOUSENUMBER', 17: 'B-S_ZIP', 18: 'B-S_CITY', 19: 'B-S_COUNTRY', 20: 'B-S_VAT', 21: 'I-S_NAME', 22: 'I-S_STREET', 23: 'I-S_HOUSENUMBER', 24: 'I-S_ZIP', 25: 'I-S_CITY', 26: 'I-S_COUNTRY', 27: 'I-S_VAT', 28: 'B-S_BANK', 29: 'B-S_BIC', 30: 'B-S_IBAN', 31: 'B-S_TEL', 32: 'B-S_EMAIL', 33: 'I-S_BANK', 34: 'I-S_BIC', 35: 'I-S_IBAN', 36: 'I-S_TEL', 37: 'I-S_EMAIL', 38: 'B-I_NUMBER', 39: 'B-I_DATE', 40: 'B-I_DUEDATE', 41: 'B-I_AMOUNT', 42: 'B-I_CURRENCY', 43: 'I-I_NUMBER', 44: 'I-I_DATE', 45: 'I-I_DUEDATE', 46: 'I-I_AMOUNT', 47: 'I-I_CURRENCY', 48: 'OTHER'}\n"
     ]
    }
   ],
   "source": [
    "id2label = {k:v for k,v in enumerate(labels)}\n",
    "label2id = {v:k for k,v in enumerate(labels)}\n",
    "print(id2label)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Habram\\Anaconda3\\envs\\LayoutXLM\\lib\\site-packages\\transformers\\models\\layoutlmv2\\feature_extraction_layoutlmv2.py:30: FutureWarning: The class LayoutLMv2FeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use LayoutLMv2ImageProcessor instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import LayoutLMv2FeatureExtractor, LayoutXLMTokenizer\n",
    "\n",
    "feature_extractor = LayoutLMv2FeatureExtractor(apply_ocr=False)\n",
    "tokenizer = LayoutXLMTokenizer.from_pretrained(\"microsoft/layoutxlm-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import PreTrainedTokenizerBase\n",
    "from transformers.file_utils import PaddingStrategy\n",
    "from torch.utils.data import DataLoader\n",
    "from dataclasses import dataclass\n",
    "import torch\n",
    "\n",
    "from typing import Optional, Union\n",
    "\n",
    "@dataclass\n",
    "class DataCollatorForTokenClassification:\n",
    "    \"\"\"\n",
    "    Data collator that will dynamically pad the inputs received, as well as the labels.\n",
    "    \n",
    "    Args:\n",
    "        tokenizer (:class:`~transformers.PreTrainedTokenizer` or :class:`~transformers.PreTrainedTokenizerFast`):\n",
    "            The tokenizer used for encoding the data.\n",
    "        padding (:obj:`bool`, :obj:`str` or :class:`~transformers.file_utils.PaddingStrategy`, `optional`, defaults to :obj:`True`):\n",
    "            Select a strategy to pad the returned sequences (according to the model's padding side and padding index)\n",
    "            among:\n",
    "            * :obj:`True` or :obj:`'longest'`: Pad to the longest sequence in the batch (or no padding if only a single\n",
    "              sequence if provided).\n",
    "            * :obj:`'max_length'`: Pad to a maximum length specified with the argument :obj:`max_length` or to the\n",
    "              maximum acceptable input length for the model if that argument is not provided.\n",
    "            * :obj:`False` or :obj:`'do_not_pad'` (default): No padding (i.e., can output a batch with sequences of\n",
    "              different lengths).\n",
    "        max_length (:obj:`int`, `optional`):\n",
    "            Maximum length of the returned list and optionally padding length (see above).\n",
    "        pad_to_multiple_of (:obj:`int`, `optional`):\n",
    "            If set will pad the sequence to a multiple of the provided value.\n",
    "            This is especially useful to enable the use of Tensor Cores on NVIDIA hardware with compute capability >=\n",
    "            7.5 (Volta).\n",
    "        label_pad_token_id (:obj:`int`, `optional`, defaults to -100):\n",
    "            The id to use when padding the labels (-100 will be automatically ignore by PyTorch loss functions).\n",
    "    \"\"\"\n",
    "\n",
    "    feature_extractor: LayoutLMv2FeatureExtractor\n",
    "    tokenizer: PreTrainedTokenizerBase\n",
    "    padding: Union[bool, str, PaddingStrategy] = True\n",
    "    max_length: Optional[int] = None\n",
    "    pad_to_multiple_of: Optional[int] = None\n",
    "    label_pad_token_id: int = -100\n",
    "\n",
    "    def __call__(self, features):\n",
    "        # prepare image input\n",
    "        image = self.feature_extractor([feature[\"image\"] for feature in features], return_tensors=\"pt\").pixel_values\n",
    "\n",
    "        # prepare text input\n",
    "        for feature in features:\n",
    "            del feature[\"image\"]\n",
    "            del feature[\"id\"]\n",
    "            del feature[\"original_image\"]\n",
    "            del feature[\"tokens\"]\n",
    "            del feature[\"relations\"]\n",
    "        \n",
    "        batch = self.tokenizer.pad(\n",
    "            features,\n",
    "            padding=self.padding,\n",
    "            max_length=self.max_length,\n",
    "            pad_to_multiple_of=self.pad_to_multiple_of,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "        batch[\"image\"] = image\n",
    "            \n",
    "        return batch\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(\n",
    "    feature_extractor,\n",
    "    tokenizer,\n",
    "    pad_to_multiple_of=None,\n",
    "    padding=\"max_length\",\n",
    "    max_length=512,\n",
    ")\n",
    "\n",
    "train_dataset = dataset['train']\n",
    "test_dataset = dataset['test']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create PyTorch DataLoader (for verification of collate function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "dataloader = DataLoader(train_dataset, batch_size=4, collate_fn=data_collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'original_image'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m batch \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m(\u001b[39miter\u001b[39;49m(dataloader))\n\u001b[0;32m      3\u001b[0m \u001b[39mfor\u001b[39;00m k,v \u001b[39min\u001b[39;00m batch\u001b[39m.\u001b[39mitems():\n\u001b[0;32m      4\u001b[0m   \u001b[39mprint\u001b[39m(k, v\u001b[39m.\u001b[39mshape)\n",
      "File \u001b[1;32mc:\\Users\\Habram\\Anaconda3\\envs\\LayoutXLM\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    631\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    632\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 633\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    634\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    635\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    636\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\Habram\\Anaconda3\\envs\\LayoutXLM\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:677\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    675\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    676\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 677\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    678\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    679\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\Habram\\Anaconda3\\envs\\LayoutXLM\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n\u001b[1;32m---> 54\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcollate_fn(data)\n",
      "Cell \u001b[1;32mIn[17], line 51\u001b[0m, in \u001b[0;36mDataCollatorForTokenClassification.__call__\u001b[1;34m(self, features)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[39mdel\u001b[39;00m feature[\u001b[39m\"\u001b[39m\u001b[39mimage\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m     50\u001b[0m \u001b[39mdel\u001b[39;00m feature[\u001b[39m\"\u001b[39m\u001b[39mid\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m---> 51\u001b[0m \u001b[39mdel\u001b[39;00m feature[\u001b[39m\"\u001b[39m\u001b[39moriginal_image\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m     52\u001b[0m \u001b[39mdel\u001b[39;00m feature[\u001b[39m\"\u001b[39m\u001b[39mentities\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m     53\u001b[0m \u001b[39mdel\u001b[39;00m feature[\u001b[39m\"\u001b[39m\u001b[39mrelations\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "\u001b[1;31mKeyError\u001b[0m: 'original_image'"
     ]
    }
   ],
   "source": [
    "batch = next(iter(dataloader))\n",
    "\n",
    "for k,v in batch.items():\n",
    "  print(k, v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LayoutXLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
