{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset istvoices_dataset (C:/Users/Habram/.cache/istvoices_dataset/default/0.0.0/07bb159fcd7e5fd88962d0d6ca202549a4212b7b1caa7b79cc7108797eb8d1c0)\n",
      "c:\\Users\\Habram\\Anaconda3\\envs\\LayoutLMv3\\lib\\site-packages\\gradio\\inputs.py:259: UserWarning: Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your component from gradio.components\n",
      "  warnings.warn(\n",
      "c:\\Users\\Habram\\Anaconda3\\envs\\LayoutLMv3\\lib\\site-packages\\gradio\\inputs.py:262: UserWarning: `optional` parameter is deprecated, and it has no effect\n",
      "  super().__init__(\n",
      "c:\\Users\\Habram\\Anaconda3\\envs\\LayoutLMv3\\lib\\site-packages\\gradio\\outputs.py:43: UserWarning: Usage of gradio.outputs is deprecated, and will not be supported in the future, please import your components from gradio.components\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Habram\\Anaconda3\\envs\\LayoutLMv3\\lib\\site-packages\\transformers\\modeling_utils.py:879: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.system('pip install git+https://github.com/huggingface/transformers.git --upgrade')\n",
    "os.system('pip install pyyaml==5.1')\n",
    "# workaround: install old version of pytorch since detectron2 hasn't released packages for pytorch 1.9 (issue: https://github.com/facebookresearch/detectron2/issues/3158)\n",
    "os.system('pip install torch==1.8.0+cu101 torchvision==0.9.0+cu101 -f https://download.pytorch.org/whl/torch_stable.html')\n",
    "\n",
    "# install detectron2 that matches pytorch 1.8\n",
    "# See https://detectron2.readthedocs.io/tutorials/install.html for instructions\n",
    "os.system('pip install -q detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu101/torch1.8/index.html')\n",
    "\n",
    "## install PyTesseract\n",
    "os.system('pip install -q pytesseract')\n",
    "\n",
    "import gradio as gr\n",
    "import numpy as np\n",
    "from transformers import LayoutLMv3Processor, AutoModelForTokenClassification\n",
    "from datasets import load_dataset\n",
    "from PIL import ImageDraw, ImageFont\n",
    "import pytesseract\n",
    "\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'\n",
    "\n",
    "processor = LayoutLMv3Processor.from_pretrained(\"microsoft/layoutlmv3-base\")\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"ihabram/LayoutLMv3_IstVoices\")\n",
    "\n",
    "# load image example\n",
    "dataset = load_dataset(r'C:\\Users\\Habram\\Documents\\thesis-masters\\invoice_generation\\istvoices_dataset.py', \n",
    "                                  cache_dir=r'C:\\Users\\Habram\\.cache', split=\"test\")\n",
    "image = dataset[2][\"image\"]\n",
    "\n",
    "# define id2label, label2color\n",
    "labels = dataset.features['ner_tags'].feature.names\n",
    "id2label = {v: k for v, k in enumerate(labels)}\n",
    "label2color = {\n",
    "        'r_name':           'lightcoral',\n",
    "        'r_street':         'brown',\n",
    "        'r_housenumber':    'red', \n",
    "        'r_zip':            'Salmon',\n",
    "        'r_city':           'chocolate',\n",
    "        'r_country':        'Sandybrown',\n",
    "        'r_vat':            'Sienna',\n",
    "        's_name':           'olive',      \n",
    "        's_street':         'yellowgreen',\n",
    "        's_housenumber':    'lawngreen',\n",
    "        's_zip':            'palegreen',\n",
    "        's_city':           'forestgreen',\n",
    "        's_country':        'limegreen',\n",
    "        's_vat':            'mediumaquamarine',\n",
    "        's_bank':           'darkgreen',\n",
    "        's_bic':            'yellow',\n",
    "        's_iban':           'teal',\n",
    "        's_tel':            'beige',\n",
    "        's_email':          'moccasin',\n",
    "        'i_number':         'aqua',\n",
    "        'i_date':           'deepskyblue',\n",
    "        'i_duedate':        'royalblue',\n",
    "        'i_amount':         'blue',\n",
    "        'i_currency':       'orange',\n",
    "        'other':            'magenta'\n",
    "    }\n",
    "\n",
    "def unnormalize_box(bbox, width, height):\n",
    "     return [\n",
    "         width * (bbox[0] / 1000),\n",
    "         height * (bbox[1] / 1000),\n",
    "         width * (bbox[2] / 1000),\n",
    "         height * (bbox[3] / 1000),\n",
    "     ]\n",
    "\n",
    "def iob_to_label(label):\n",
    "    label = label[2:]\n",
    "    if not label:\n",
    "      return 'other'\n",
    "    return label\n",
    "\n",
    "def process_image(image):\n",
    "    width, height = image.size\n",
    "\n",
    "    # encode\n",
    "    encoding = processor(image, truncation=True, return_offsets_mapping=True, return_tensors=\"pt\")\n",
    "    offset_mapping = encoding.pop('offset_mapping')\n",
    "\n",
    "    # forward pass\n",
    "    outputs = model(**encoding)\n",
    "\n",
    "    # get predictions\n",
    "    predictions = outputs.logits.argmax(-1).squeeze().tolist()\n",
    "    token_boxes = encoding.bbox.squeeze().tolist()\n",
    "\n",
    "    # only keep non-subword predictions\n",
    "    is_subword = np.array(offset_mapping.squeeze().tolist())[:,0] != 0\n",
    "    true_predictions = [id2label[pred] for idx, pred in enumerate(predictions) if not is_subword[idx]]\n",
    "    true_boxes = [unnormalize_box(box, width, height) for idx, box in enumerate(token_boxes) if not is_subword[idx]]\n",
    "\n",
    "    # draw predictions over the image\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    font = ImageFont.load_default()\n",
    "    for prediction, box in zip(true_predictions, true_boxes):\n",
    "        predicted_label = iob_to_label(prediction).lower()\n",
    "        draw.rectangle(box, outline=label2color[predicted_label])\n",
    "        draw.text((box[0]+10, box[1]-10), text=predicted_label, fill=label2color[predicted_label], font=font)\n",
    "    \n",
    "    return image\n",
    "\n",
    "title = \"Interactive demo: LayoutLMv3 istvoices dataset\"\n",
    "description = \"Demo for Microsoft's LayoutLMv3, a Transformer for state-of-the-art document image understanding tasks.\"\n",
    "article = \"LayoutLMv3: Pre-training for Document AI with Unified Text and Image Masking\"\n",
    "\n",
    "css = \"\"\".output_image, .input_image {height: 600px !important}\"\"\"\n",
    "\n",
    "iface = gr.Interface(fn=process_image, \n",
    "                     inputs=gr.inputs.Image(type=\"pil\"), \n",
    "                     outputs=gr.outputs.Image(type=\"pil\", label=\"annotated image\"),\n",
    "                     title=title,\n",
    "                     description=description,\n",
    "                     article=article,\n",
    "                     css=css)\n",
    "iface.launch(debug=True, share=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LayoutLMv3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
