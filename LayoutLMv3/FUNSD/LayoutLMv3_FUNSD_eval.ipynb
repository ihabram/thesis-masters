{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset funsd-layoutlmv3 (C:/Users/Habram/.cache/huggingface/datasets/nielsr___funsd-layoutlmv3/funsd/1.0.0/0e3f4efdfd59aa1c3b4952c517894f7b1fc4d75c12ef01bcc8626a69e41c1bb9)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69391a2c111749e6a8a268a03cc774fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset \n",
    "\n",
    "# this dataset uses the new Image feature :)\n",
    "dataset = load_dataset(\"nielsr/funsd-layoutlmv3\")\n",
    "\n",
    "from transformers import AutoProcessor\n",
    "\n",
    "# we'll use the Auto API here - it will load LayoutLMv3Processor behind the scenes,\n",
    "# based on the checkpoint we provide from the hub\n",
    "processor = AutoProcessor.from_pretrained(\"microsoft/layoutlmv3-base\", apply_ocr=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\Habram\\.cache\\huggingface\\datasets\\nielsr___funsd-layoutlmv3\\funsd\\1.0.0\\0e3f4efdfd59aa1c3b4952c517894f7b1fc4d75c12ef01bcc8626a69e41c1bb9\\cache-b8cd7aaa41f679ea.arrow\n",
      "Loading cached processed dataset at C:\\Users\\Habram\\.cache\\huggingface\\datasets\\nielsr___funsd-layoutlmv3\\funsd\\1.0.0\\0e3f4efdfd59aa1c3b4952c517894f7b1fc4d75c12ef01bcc8626a69e41c1bb9\\cache-d5c4c7cf6684c166.arrow\n"
     ]
    }
   ],
   "source": [
    "from datasets.features import ClassLabel\n",
    "\n",
    "features = dataset[\"train\"].features\n",
    "column_names = dataset[\"train\"].column_names\n",
    "image_column_name = \"image\"\n",
    "text_column_name = \"tokens\"\n",
    "boxes_column_name = \"bboxes\"\n",
    "label_column_name = \"ner_tags\"\n",
    "\n",
    "# In the event the labels are not a `Sequence[ClassLabel]`, we will need to go through the dataset to get the\n",
    "# unique labels.\n",
    "def get_label_list(labels):\n",
    "    unique_labels = set()\n",
    "    for label in labels:\n",
    "        unique_labels = unique_labels | set(label)\n",
    "    label_list = list(unique_labels)\n",
    "    label_list.sort()\n",
    "    return label_list\n",
    "\n",
    "if isinstance(features[label_column_name].feature, ClassLabel):\n",
    "    label_list = features[label_column_name].feature.names\n",
    "    # No need to convert the labels since they are already ints.\n",
    "    id2label = {k: v for k,v in enumerate(label_list)}\n",
    "    label2id = {v: k for k,v in enumerate(label_list)}\n",
    "else:\n",
    "    label_list = get_label_list(dataset[\"train\"][label_column_name])\n",
    "    id2label = {k: v for k,v in enumerate(label_list)}\n",
    "    label2id = {v: k for k,v in enumerate(label_list)}\n",
    "num_labels = len(label_list)\n",
    "\n",
    "def prepare_examples(examples):\n",
    "  images = examples[image_column_name]\n",
    "  words = examples[text_column_name]\n",
    "  boxes = examples[boxes_column_name]\n",
    "  word_labels = examples[label_column_name]\n",
    "\n",
    "  encoding = processor(images, words, boxes=boxes, word_labels=word_labels,\n",
    "                       truncation=True, padding=\"max_length\")\n",
    "\n",
    "  return encoding\n",
    "\n",
    "from datasets import Features, Sequence, ClassLabel, Value, Array2D, Array3D\n",
    "\n",
    "# we need to define custom features for `set_format` (used later on) to work properly\n",
    "features = Features({\n",
    "    'pixel_values': Array3D(dtype=\"float32\", shape=(3, 224, 224)),\n",
    "    'input_ids': Sequence(feature=Value(dtype='int64')),\n",
    "    'attention_mask': Sequence(Value(dtype='int64')),\n",
    "    'bbox': Array2D(dtype=\"int64\", shape=(512, 4)),\n",
    "    'labels': Sequence(feature=Value(dtype='int64')),\n",
    "})\n",
    "\n",
    "train_dataset = dataset[\"train\"].map(\n",
    "    prepare_examples,\n",
    "    batched=True,\n",
    "    remove_columns=column_names,\n",
    "    features=features,\n",
    ")\n",
    "eval_dataset = dataset[\"test\"].map(\n",
    "    prepare_examples,\n",
    "    batched=True,\n",
    "    remove_columns=column_names,\n",
    "    features=features,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from seqeval.metrics import classification_report\n",
    "from datasets import load_metric\n",
    "\n",
    "metric = load_metric(\"seqeval\")\n",
    "\n",
    "return_entity_level_metrics = True\n",
    "\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    # Remove ignored index (special tokens)\n",
    "    true_predictions = [\n",
    "        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    true_labels = [\n",
    "        [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "\n",
    "    results = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "    if return_entity_level_metrics:\n",
    "        # Unpack nested dictionaries\n",
    "        final_results = {}\n",
    "        for key, value in results.items():\n",
    "            if isinstance(value, dict):\n",
    "                for n, v in value.items():\n",
    "                    final_results[f\"{key}_{n}\"] = v\n",
    "            else:\n",
    "                final_results[key] = value\n",
    "        return final_results\n",
    "    else:\n",
    "        return {\n",
    "            \"precision\": results[\"overall_precision\"],\n",
    "            \"recall\": results[\"overall_recall\"],\n",
    "            \"f1\": results[\"overall_f1\"],\n",
    "            \"accuracy\": results[\"overall_accuracy\"],\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForTokenClassification\n",
    "\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"test/checkpoint-1000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "training_args = TrainingArguments(output_dir=\"test\",\n",
    "                                  max_steps=1000,\n",
    "                                  per_device_train_batch_size=2,\n",
    "                                  per_device_eval_batch_size=2,\n",
    "                                  learning_rate=1e-5,\n",
    "                                  evaluation_strategy=\"steps\",\n",
    "                                  eval_steps=100,\n",
    "                                  load_best_model_at_end=True,\n",
    "                                  metric_for_best_model=\"f1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.data.data_collator import default_data_collator\n",
    "\n",
    "# Initialize our Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    tokenizer=processor,\n",
    "    data_collator=default_data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Habram\\Anaconda3\\envs\\LayoutLMv3\\lib\\site-packages\\transformers\\modeling_utils.py:879: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87da656a9c0b4f309a3cebc249f97547",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.5227469  -0.61665034 -0.72801656 ... -0.5851758  -0.59295017\n",
      "    0.1891223 ]\n",
      "  [-1.2408422   1.1296552  -2.1369545  ... -1.2010559  -1.888513\n",
      "   -2.1990263 ]\n",
      "  [-1.301788   -1.0314339  -1.0290934  ...  4.3501344  -2.3781564\n",
      "   -1.5551789 ]\n",
      "  ...\n",
      "  [ 0.514364   -0.6048404  -0.7255876  ... -0.5872829  -0.5809066\n",
      "    0.18480977]\n",
      "  [ 0.514364   -0.6048404  -0.7255876  ... -0.5872829  -0.5809066\n",
      "    0.18480977]\n",
      "  [ 0.514364   -0.6048404  -0.7255876  ... -0.5872829  -0.5809066\n",
      "    0.18480977]]\n",
      "\n",
      " [[ 0.48502555 -0.49840876 -0.8495505  ... -0.44594455 -0.5907527\n",
      "    0.22827671]\n",
      "  [-0.5603218   1.0881749  -2.4192579  ... -1.04953    -1.636013\n",
      "   -2.1455333 ]\n",
      "  [-0.23497693 -1.0392225  -1.1466985  ...  4.1440706  -2.9664743\n",
      "   -1.4228077 ]\n",
      "  ...\n",
      "  [ 0.482246   -0.49599653 -0.84252983 ... -0.45163774 -0.58099794\n",
      "    0.23516463]\n",
      "  [ 0.482246   -0.49599653 -0.84252983 ... -0.45163774 -0.58099794\n",
      "    0.23516463]\n",
      "  [ 0.482246   -0.49599653 -0.84252983 ... -0.45163774 -0.58099794\n",
      "    0.23516463]]\n",
      "\n",
      " [[ 0.22837053 -0.55095845 -0.6115066  ... -0.71992904 -0.6694883\n",
      "    0.713334  ]\n",
      "  [-1.5477511   1.3288224  -2.0476623  ... -1.0667582  -1.7052532\n",
      "   -2.2365797 ]\n",
      "  [-1.8990752  -0.9075247  -0.34785908 ...  5.1691976  -2.4490237\n",
      "   -1.6586797 ]\n",
      "  ...\n",
      "  [ 0.23640178 -0.53965676 -0.6037003  ... -0.7196738  -0.6432041\n",
      "    0.6736153 ]\n",
      "  [ 0.23640178 -0.53965676 -0.6037003  ... -0.7196738  -0.6432041\n",
      "    0.6736153 ]\n",
      "  [ 0.23640178 -0.53965676 -0.6037003  ... -0.7196738  -0.6432041\n",
      "    0.6736153 ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 0.46696225 -0.33752146 -0.7111867  ... -0.4848489  -0.5690359\n",
      "    0.14446078]\n",
      "  [ 2.7497594   0.3585556  -2.4945421  ... -2.5618668   2.166657\n",
      "   -3.254903  ]\n",
      "  [ 3.6411693  -1.2145449  -2.515357   ... -1.3727541   1.7382729\n",
      "   -2.1770694 ]\n",
      "  ...\n",
      "  [ 1.8562846  -2.0040686  -1.9517342  ... -0.79899496 -0.7663326\n",
      "    5.5847487 ]\n",
      "  [ 1.805669   -1.8913097  -2.0317488  ... -0.83644915 -0.9090259\n",
      "    5.6825604 ]\n",
      "  [ 0.46161243 -0.33786517 -0.7102124  ... -0.4886822  -0.56617534\n",
      "    0.14599526]]\n",
      "\n",
      " [[ 0.5649984  -0.49467066 -0.639678   ... -0.43301398 -0.526881\n",
      "    0.2348118 ]\n",
      "  [ 2.228934    1.0937142  -2.7533593  ... -2.63093    -0.09911398\n",
      "   -2.7853818 ]\n",
      "  [ 2.3684328  -0.11654403 -1.4485317  ...  0.01067589 -1.1325582\n",
      "   -1.5581894 ]\n",
      "  ...\n",
      "  [ 3.9414349   1.2645464  -2.5912435  ... -2.5152476  -0.78796124\n",
      "   -2.2937956 ]\n",
      "  [ 3.9406872   1.2653117  -2.590863   ... -2.5156484  -0.7876439\n",
      "   -2.2935762 ]\n",
      "  [ 3.9403644   1.2650696  -2.5908673  ... -2.5154977  -0.7875029\n",
      "   -2.2934475 ]]\n",
      "\n",
      " [[ 0.6291163  -0.36720046 -0.6572562  ... -0.46280015 -0.60608315\n",
      "    0.2799028 ]\n",
      "  [ 1.7771351   0.11577434 -2.6847584  ... -0.18338203 -1.8052286\n",
      "   -2.5154617 ]\n",
      "  [ 1.6160351  -1.5581958  -1.6395189  ...  4.086816   -2.6085072\n",
      "   -1.4731483 ]\n",
      "  ...\n",
      "  [ 4.070109   -1.7183429  -2.394438   ...  3.4593964  -2.549795\n",
      "   -1.3487508 ]\n",
      "  [ 4.300472   -1.7325875  -2.6333747  ...  3.0707781  -2.3571281\n",
      "   -1.2332996 ]\n",
      "  [ 0.6269585  -0.36465105 -0.6580593  ... -0.46524087 -0.60163426\n",
      "    0.27458602]]]\n"
     ]
    }
   ],
   "source": [
    "result = trainer.predict(eval_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.argmax(result[0], axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 512)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68db398d82d544638d40c7c27538a5a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello!\n",
      "<transformers.trainer_utils.EvalPrediction object at 0x000001921DEFD6A0>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.5202368497848511,\n",
       " 'eval_ANSWER_precision': 0.892271662763466,\n",
       " 'eval_ANSWER_recall': 0.9326805385556916,\n",
       " 'eval_ANSWER_f1': 0.9120287253141832,\n",
       " 'eval_ANSWER_number': 817,\n",
       " 'eval_HEADER_precision': 0.6972477064220184,\n",
       " 'eval_HEADER_recall': 0.6386554621848739,\n",
       " 'eval_HEADER_f1': 0.6666666666666666,\n",
       " 'eval_HEADER_number': 119,\n",
       " 'eval_QUESTION_precision': 0.910665451230629,\n",
       " 'eval_QUESTION_recall': 0.9275766016713092,\n",
       " 'eval_QUESTION_f1': 0.9190432382704692,\n",
       " 'eval_QUESTION_number': 1077,\n",
       " 'eval_overall_precision': 0.891747572815534,\n",
       " 'eval_overall_recall': 0.912568306010929,\n",
       " 'eval_overall_f1': 0.9020378099680825,\n",
       " 'eval_overall_accuracy': 0.8655651967193629,\n",
       " 'eval_runtime': 10.5125,\n",
       " 'eval_samples_per_second': 4.756,\n",
       " 'eval_steps_per_second': 2.378}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LayoutLMv3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
